{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e76f43a-c01d-4069-89fb-38217ee2b7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if 'workbookDir' not in globals():\n",
    "    print('Updating working directory')\n",
    "    workbookDir = os.path.dirname(os.getcwd())\n",
    "    os.chdir(workbookDir)\n",
    "print(os.getcwd())\n",
    "\n",
    "from python_code.util import  preprocess\n",
    "from python_code.util.binary_loss import BinaryLoss\n",
    "from trace_brightfield.util_deep_learning import predict_3D_stack\n",
    "from trace_brightfield.UNet_3D_model import UNet_3D\n",
    "\n",
    "import tifffile\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import tensor\n",
    "import numpy as np\n",
    "from torch import nn, cat\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import ReLU, MaxPool3d, MSELoss, ConvTranspose3d, Conv3d,BCELoss, CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edb5a04-39a4-491e-bb3e-4da4ec6881fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, folder_imgs, folder_targets):\n",
    "        self.folder_imgs = folder_imgs\n",
    "        self.folder_targets = folder_targets\n",
    "        valid_suffix = {'.tif'}\n",
    "        \n",
    "        self.file_names = [p.name for p in Path(self.folder_imgs).iterdir() if p.suffix in valid_suffix] \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "\n",
    "        img = tifffile.imread(Path(self.folder_imgs,file_name))\n",
    "        target = tifffile.imread(Path(self.folder_targets,file_name))\n",
    "\n",
    "        # Preprocess image for normalization\n",
    "        #img = preprocess.preprocess_3d_stack_for_AI_segmentation(img)\n",
    "\n",
    "        # Perform simple data augmentation\n",
    "        if np.random.uniform(0, 1) > 0.5:\n",
    "            # randomly invert x-axis\n",
    "            img[:,::-1,:]\n",
    "\n",
    "        if np.random.uniform(0, 1) > 0.5:\n",
    "            # randomly invert y-axis\n",
    "            img[:,:,::-1]\n",
    "        '''\n",
    "        if np.random.uniform(0, 1) > 0.5:\n",
    "            img += np.random.uniform(-0.1, 0.1)\n",
    "        '''\n",
    "        \n",
    "        #img is a 3D image with [D,W,H], We require a 4D stack [C,D,W,H] where C is the number of channels. In this case 1.\n",
    "        img = tensor(img).float().unsqueeze(0)\n",
    "        target = tensor(target).float().unsqueeze(0)\n",
    "        \n",
    "        return  img, target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ed61e7-a1d1-43cc-8159-27b50f92d95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_imgs = r\"E:\\SPERM\\Training_dataset\\2024_12_26_flagellum_head_brightfield\\input\"\n",
    "folder_targets = r\"E:\\SPERM\\Training_dataset\\2024_12_26_flagellum_head_brightfield\\target\"\n",
    "dataset = CustomImageDataset(folder_imgs,folder_targets)\n",
    "img, target = dataset.__getitem__(0)\n",
    "\n",
    "# Create the dataloader\n",
    "train_dataloader = DataLoader(dataset, batch_size= 16, shuffle=True, num_workers=0, drop_last=True)\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"The total of images in dataset is: {dataset.__len__()}\")\n",
    "print(f\"The input image shape is: {img.shape}\")\n",
    "print(f\"Running device: {device}\")\n",
    "\"\"\"\n",
    "sample_batch = next(iter(train_dataloader))\n",
    "images,targets = sample_batch\n",
    "\n",
    "# plot some training images\n",
    "fig, axes = plt.subplots(4, 4, figsize=(12, 12))  # Create a 4x4 grid to hold two 4x2 groups of images\n",
    "# Flatten the axes for easier iteration\n",
    "axes = axes.flatten()\n",
    "# Plot images for the first figure in the first 8 subplots\n",
    "for i in range(8):\n",
    "    ax = axes[2*i]\n",
    "    ax.imshow(np.max(images[i].squeeze(0).cpu().numpy(),axis=0), cmap='gray')\n",
    "    ax.axis('off')  # Turn off axis labels and ticks\n",
    "    ax = axes[2*i+1]\n",
    "    ax.imshow(np.max(targets[i].squeeze(0).cpu().numpy(),axis=0), cmap='gray')\n",
    "    ax.axis('off')  # Turn off axis labels and ticks    \n",
    "\n",
    "# Adjust layout and display\n",
    "plt.tight_layout()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767f8d02-9d10-4fd1-a1e9-9be027e13718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_samples(folder_path, model, device, label=\"\"):\n",
    "    folder_output = Path(folder_path, \"results\")\n",
    "    folder_output.mkdir(parents=True, exist_ok=True)\n",
    "    file_names = [p.name for p in Path(folder_path).iterdir() if p.suffix in {'.tif'}]\n",
    "\n",
    "    if not isinstance(label, str):\n",
    "        label = f\"{label:05}\"\n",
    "        \n",
    "    if len(file_names)>0:\n",
    "        # plot some training images\n",
    "        fig, axes = plt.subplots(len(file_names), 2, figsize=(12, 12))  # Create a Nx2 grid to hold the predictions\n",
    "        # Flatten the axes for easier iteration\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i,fn in enumerate(file_names):\n",
    "            # make prediction\n",
    "            img = tifffile.imread(Path(folder_path, fn))\n",
    "            network_output = predict_3D_stack(img, model, device = device)\n",
    "    \n",
    "            #plot images\n",
    "            ax = axes[2*i]\n",
    "            ax.imshow(np.max(img,axis=0), cmap='gray')        \n",
    "            ax.axis('off')  # Turn off axis labels and ticks\n",
    "    \n",
    "            #plot predictions\n",
    "            ax = axes[2*i+1]\n",
    "            ax.imshow(np.max(network_output,axis=0), cmap='gray')        \n",
    "            ax.axis('off')  # Turn off axis labels and ticks\n",
    "            tifffile.imwrite(Path(folder_output,f\"Network_output_{Path(fn).stem}_epoch_{label}.tif\"), network_output)\n",
    "        plt.savefig(Path(folder_output, f\"Network_output_epoch_{label}\"))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114c7683-1c30-497c-9e6c-f1e4afc42f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model and test it\n",
    "modelo = UNet_3D().to(device)\n",
    "#modelo.load_state_dict(torch.load(r\"E:\\SPERM\\Training_dataset\\2024_12_24_flagellum_head_brightfield\\model\\modelo_UNet_3D_epoch_00099.pth\", weights_only=True))\n",
    "X = torch.rand(size=(10,1, 9, 101, 96), dtype=torch.float32, device=device)        \n",
    "out = modelo(X)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a13fe73-5aae-4d75-b2b2-cf99c27330ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "BCE_loss = BCELoss()\n",
    "Binary_loss = BinaryLoss()\n",
    "optimizer = Adam(modelo.parameters(), lr = 0.001)\n",
    "\n",
    "# folder with test images to check the performance in unseen images\n",
    "folder_test = r\"E:\\SPERM\\Training_dataset\\2024_12_24_flagellum_head_brightfield\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc22278-c806-468c-8cf4-66dd25ab1433",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(100):\n",
    "    #set the model in training mode\n",
    "    modelo.train()\n",
    "    epoch_error = 0\n",
    "    counter = 0\n",
    "    for imgs, targets in train_dataloader:\n",
    "        # Change anotations to float\n",
    "        targets = targets.float().to(device)\n",
    "        imgs = imgs.float().to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # sets to zero the gradients of the optimizer\n",
    "        \n",
    "        network_output = modelo(imgs) # forward pass\n",
    "    \n",
    "        loss = Binary_loss(torch.sigmoid(network_output), targets) #+ BCE_loss(torch.sigmoid(network_output), targets) # Loss function\n",
    "        #loss = BCE_loss(torch.sigmoid(network_output), targets)  # Loss function\n",
    "\n",
    "        loss.backward() # compute the gradients given|| the loss value\n",
    "    \n",
    "        optimizer.step() # update the weights of models using the gradients and the given optimizer\n",
    "\n",
    "        epoch_error+=loss.item()\n",
    "\n",
    "        counter+=1\n",
    "\n",
    "    if epoch%5==0:\n",
    "        torch.save(modelo.state_dict(), f'modelo_UNet_3D_epoch_{epoch:05}.pth')\n",
    "    print(f\"El error epoch = {epoch} es {epoch_error/counter}\")\n",
    "    save_samples(folder_test, modelo, device, label=epoch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4dcc55-ba09-4e46-8fed-814d06de20d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(modelo.state_dict(), 'full_model.pth')\n",
    "print(\"Entire model saved!\")\n",
    "\n",
    "modelo_final = UNet_3D().to(device)  # Reinitialize model\n",
    "modelo_final.load_state_dict(torch.load('full_model.pth', weights_only=True))\n",
    "\n",
    "save_samples(folder_test, modelo_final, device, label=\"_final\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
